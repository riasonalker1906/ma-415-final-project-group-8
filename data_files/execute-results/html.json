{
  "hash": "dc2d3eac1c6701a68801d6f0ce3d4198",
  "result": {
    "markdown": "---\ntitle: Data\ndescription: We describe the sources of our data and the cleaning process.\ntoc: true\ndraft: false\n---\n\n\n![](images/data-import-cheatsheet-thumbs.png)\n\n\nThis comes from the file `data.qmd`.\n\nYour first steps in this project will be to find data to work on.\n\nI recommend trying to find data that interests you and that you are knowledgeable about. A bad example would be if you have no interest in video games but your data set is about video games. I also recommend finding data that is related to current events, social justice, and other areas that have an impact.\n\n\nInitially, you will study _one dataset_ but later you will need to combine that data with another dataset. For this reason, I recommend finding data that has some date and/or location components. These types of data are conducive to interesting visualizations and analysis and you can also combine this data with other data that also has a date or location variable.\nData from the census, weather data, economic data, are all relatively easy to combine with other data with time/location components.\n\n\n## What makes a good data set?\n\n* Data you are interested in and care about.\n* Data where there are a lot of potential questions that you can explore.\n* A data set that isn't completely cleaned already.\n* Multiple sources for data that you can combine.\n* Some type of time and/or location component.\n\n\n## Where to keep data?\n\n\nBelow 50mb: In `dataset` folder\n\nAbove 50mb: In `dataset_ignore` folder. This folder will be ignored by `git` so you'll have to manually sync these files across your team.\n\n### Sharing your data\n\n\nFor small datasets (<50mb), you can use the `dataset` folder that is tracked by github. Add the files just like you would any other file.\n\nIf you create a folder named `data` this will cause problems.\n\nFor larger datasets, you'll need to create a new folder in the project root directory named `dataset-ignore`. This will be ignored by git (based off the `.gitignore` file in the project root directory) which will help you avoid issues with Github's size limits. Your team will have to manually make sure the data files in `dataset-ignore` are synced across team members.\n\nYour [load_and_clean_data.R](/scripts/load_and_clean_data.R) file is how you will load and clean your data. Here is a an example of a very simple one.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\n  \"scripts/load_and_clean_data.R\",\n  echo = TRUE # Use echo=FALSE or omit it to avoid code output  \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n> library(tidyverse)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n> loan_data <- read_csv(here::here(\"dataset\", \"loan_refusal.csv\"))\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 20 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): bank\ndbl (4): min, white, himin, hiwhite\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n> loan_data_clean <- pivot_longer(loan_data, 2:5, names_to = \"group\", \n+     values_to = \"refusal_rate\")\n\n> write_rds(loan_data_clean, file = here::here(\"dataset\", \n+     \"loan_refusal_clean.rds\"))\n```\n:::\n:::\n\nYou should never use absolute paths (eg. `/Users/danielsussman/path/to/project/` or `C:\\MA415\\\\Final_Project\\`).\n\nYou might consider using the `here` function from the [`here` package](https://here.r-lib.org/articles/here.html) to avoid path problems.\n\n### Load and clean data script\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\n  \"scripts/clean_data.R\",\n  echo = FALSE # Use echo=FALSE or omit it to avoid code output  \n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nhere() starts at /Users/maikatakemoto/Downloads/Fall 2024/MA415/Final Project/ma-4615-fa24-final-project-group-8\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 104698 Columns: 57\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (57): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There were 4 warnings in `filter()`.\nThe first warning was:\nℹ In argument: `&...`.\nCaused by warning in `` as.numeric(`School Name`) >= 0 | is.na(as.numeric(`School Name`)) ``:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.\nOne or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 104698 Columns: 57\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (57): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 104698 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (67): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There were 4 warnings in `filter()`.\nThe first warning was:\nℹ In argument: `&...`.\nCaused by warning in `` as.numeric(`School Name`) >= 0 | is.na(as.numeric(`School Name`)) ``:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 3 remaining warnings.\n```\n:::\n:::\n\n\nThe idea behind this file is that someone coming to your website could largely replicate your analyses after running this script on the original data sets to clean them.\nThis file might create a derivative data set that you then use for your subsequent analysis.\nNote that you don't need to run this script from every post/page.\nInstead, you can load in the results of this script, which could be plain text files or `.RData` files. In your data page you'll describe how these results were created. If you have a very large data set, you might save smaller data sets that you can use for exploration purposes.\nTo link to this file, you can use `[cleaning script](/scripts/load_and_clean_data.R)` which appears as [cleaning script](/scripts/load_and_clean_data.R). \n\n----\n\n## Rubric: On this page\n\nYou will\n\n* Describe where/how to find data.\n  * You must include a link to the original data source(s). Make sure to provide attribution to those who collected the data.\n  * Why was the data collected/curated? Who put it together? (This is important, if you don't know why it was collected then that might not be a good dataset to look at.\n* Describe the different data files used and what each variable means. \n  * If you have many variables then only describe the most relevant ones and summarize the rest.\n* Describe any cleaning you had to do for your data.\n  * You *must* include a link to your `load_and_clean_data.R` file.\n  * Rename variables and recode factors to make data more clear.\n  * Also, describe any additional R packages you used outside of those covered in class.\n  * Describe and show code for how you combined multiple data files and any cleaning that was necessary for that.\n  * Some repetition of what you do in your `load_and_clean_data.R` file is fine and encouraged if it helps explain what you did.\n* Organization, clarity, cleanliness of the page\n  * Make sure to remove excessive warnings, use clean easy-to-read code (without side scrolling), organize with sections, use bullets and other organization tools, etc.\n  * This page should be self-contained.\n\n\n----\n## Our work: On this page\n\nThe data (raw: https://nces.ed.gov/ccd/elsi/) comes from the National Center of \nEducation Statistics, a federal agency appointed to serve the U.S. department \nof education. The data is collected using two primary surveys: The Common Core \nof Data (CCD) and the Private School Survey (PSS). The data from these two \nsurveys come from a collection of other sources; primarily the state dropout \nand completion data file, and Local Education Agency Universal Survey. Finance \ndata was also utilized for certain variables. The Institute of Education \nSciences collected the data to analyze “education trends”, to further \ninitiatives to improve access to higher education. Finding the data from the \noriginal source is possible but tedious, as data is collected by state and \nlocally. \n\nIn our `clean_data.R` file, the code snippet utilizes the\n`tidyverse` package to handle data manipulation and analysis tasks\nefficiently. It reads in a RData file named `clean_data.R`\nlocated within the `datasets` directory using the `load()` function. The\ncleaned data is saved as an `.rds` file named `our_data_clean.rds` in\nthe `scripts` directory using the `saveRDS` function. This ensures that\nthe cleaned data set can be easily accessed and shared for future\nanalyses. Additionally, the `readRDS` function is used to read the saved\n`.rds` file, enabling the retrieval of the cleaned data set for further\nprocessing or exploration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressWarnings(\n  source(\"scripts/clean_data.R\", echo = FALSE)\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 104698 Columns: 57\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (57): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 104698 Columns: 57\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (57): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 104698 Columns: 67\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (67): School Name, State Name [Public School] Latest available year, Gra...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nCurrently, we are only looking at the one ELSI data file, but we plan to \nincorporate more as we progress in our project timeline for auxiliary analyses. \n\nThe following variables are currently included in our dataset: School Name, State Name, Grades 1-8 Students, Grades 9-12 Students, Male Students, Female Students,American Indian/Alaska Native Students, Asian or Asian/Pacific Islander Students, Hispanic Students, White Students, Nat. Hawaiian or Other Pacific Isl. Students, and Pupil/Teacher Ratio. We chose variables to analyze which we believed were likely most important contributing factors to school enrollment. Race/Ethnicity can reflect cultural \ndifferences and disparities in access to resources in segregated communities, \nthus it is important to analyze how systemic issues affect enrollment and cross\nreference grade as well to compare effects. Gender can also have a significant \neffect based on certain disparities in mental health and learning disabilities \nthat can be found between males and females. Finally, we felt Pupil/Teacher \nratio was another important factor as certain school districts in lower income \ncommunities tend to be deprived of resources (due to smaller tax base), thus \nthis could lower enrollment as parents or students may feel they get less out \nof school. \n\nData Cleaning and Preprocessing - Our initial step involved  data \ncleaning to ensure data integrity and accuracy. This included removing all \n‘NA’ values based on the following criteria:\n\n‘†’ represented data that was inapplicable, which we converted to NA for \nclarity.  \n‘-’ denoted missing data,   \nwhile ‘‡’ indicated data not meeting our quality standards.  \nBoth were also transformed to NA.  \nWe then removed rows containing any NA values to create a consistent \nand reliable dataset. Additionally, all negative values were eliminated, as they\nwere considered erroneous entries.  \nMoreover, some standardization of state names was done to ensure that we were \nnot counting duplicates of states which only differed by capitalization. \n\nFuture Dataset Restructuring. \nTo support more detailed analysis, we’re considering restructuring the dataset \nby segmenting it into various tables based on factors like academic year, grade,\nand gender. Here are two specific areas of interest:  \n\nAcademic Year - By organizing data by academic year, we can examine trends  \nimpacted by significant events like COVID-19. For instance, research suggests \nthe pandemic increased \"social avoidance,\" particularly among male students, \nleading to decreased motivation for school attendance due to diminished social interaction. Among younger students, parental choices rooted in safety habits \nestablished during the pandemic may also contribute to attendance shifts. \nBy segmenting attendance data by grade over academic years, we can better \nunderstand these nuances.  \n\nGender and Race - Our data enables us to explore how systemic issues affect \nenrollment patterns. Given the historical context of redlining and segregation \nin the U.S., students of certain racial backgrounds are more likely to reside in resource-limited areas, impacting their educational opportunities. Analyzing \nenrollment by race and gender can illuminate the ways these structural factors \nshape enrollment trends in public schools, providing insights into broader \nsocial inequities.\n\nThis restructured dataset, segmented by academic year, grade, gender, and race, \nwill allow us to uncover patterns and generate insights into the various \ninfluences on school enrollment and attendance, supporting a comprehensive \nanalysis of educational trends and their underlying factors.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}